"""
Conversational Engine - ëŒ€í™”í˜• AI ì—”ì§„ 

KITECH ê²€ì¦ íŒ¨í„´ê³¼ AdalFlow ìë™ ìµœì í™”ë¥¼ í†µí•©í•œ
ë¿Œë¦¬ì‚°ì—… ì „ìš© ëŒ€í™”í˜• AI ì±—ë´‡ ì—”ì§„.

Features:
- Ollama ê¸°ë°˜ ëŒ€í™” ìƒì„±
- AdalFlow ìë™ í”„ë¡¬í”„íŠ¸ ìµœì í™”  
- THINK ë¸”ë¡ ì‹¤ì‹œê°„ í‘œì‹œ
- í•œêµ­ì–´ íŠ¹í™” ì²˜ë¦¬
- ëŒ€í™” ë‚´ì—­ DB ì €ì¥ ë° ì¬í™œìš©
- MCP ë„êµ¬ í†µí•©
"""

import asyncio
import logging
import time
import uuid
from typing import Dict, List, Optional, Any, AsyncGenerator, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import json
import aiohttp

from ..adalflow_engine import AutoPromptOptimizer, PerformanceTracker
from .config_manager import KitechConfigManager
from .korean_optimizer import KoreanLanguageOptimizer
from .think_ui import ThinkBlockManager, ThinkLevel

logger = logging.getLogger(__name__)


@dataclass
class ConversationMessage:
    """ëŒ€í™” ë©”ì‹œì§€"""
    role: str  # user, assistant, system
    content: str
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)
    think_blocks: List[Dict[str, Any]] = field(default_factory=list)


@dataclass 
class ConversationSession:
    """ëŒ€í™” ì„¸ì…˜"""
    session_id: str
    user_id: Optional[str] = None
    messages: List[ConversationMessage] = field(default_factory=list)
    context: Dict[str, Any] = field(default_factory=dict)
    start_time: datetime = field(default_factory=datetime.now)
    last_activity: datetime = field(default_factory=datetime.now)
    industry_domain: Optional[str] = None
    optimization_state: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ConversationResult:
    """ëŒ€í™” ê²°ê³¼"""
    response: str
    session_id: str
    processing_time: float
    optimization_applied: bool = False
    performance_metrics: Dict[str, float] = field(default_factory=dict)
    think_blocks: List[Dict[str, Any]] = field(default_factory=list)
    industry_terms_detected: List[str] = field(default_factory=list)


class ConversationalEngine:
    """
    PPuRI-AI Ultimate ëŒ€í™”í˜• ì—”ì§„
    
    KITECH ê²€ì¦ëœ ì•ˆì •ì„±ê³¼ AdalFlow í˜ì‹ ì  ìµœì í™”ë¥¼ ê²°í•©í•œ
    ì°¨ì„¸ëŒ€ ë¿Œë¦¬ì‚°ì—… ì „ìš© ëŒ€í™”í˜• AI ì‹œìŠ¤í…œ.
    """
    
    def __init__(
        self,
        config_manager: KitechConfigManager,
        korean_optimizer: KoreanLanguageOptimizer,
        think_manager: ThinkBlockManager,
        auto_optimizer: Optional[AutoPromptOptimizer] = None,
        performance_tracker: Optional[PerformanceTracker] = None
    ):
        self.config_manager = config_manager
        self.korean_optimizer = korean_optimizer
        self.think_manager = think_manager
        self.auto_optimizer = auto_optimizer
        self.performance_tracker = performance_tracker
        
        # Ollama ì„¤ì •
        self.ollama_config = config_manager.get_ollama_config()
        self.ollama_session: Optional[aiohttp.ClientSession] = None
        
        # ëŒ€í™” ì„¸ì…˜ ê´€ë¦¬
        self.active_sessions: Dict[str, ConversationSession] = {}
        self.session_timeout = timedelta(hours=2)  # 2ì‹œê°„ í›„ ì„¸ì…˜ ë§Œë£Œ
        
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        self.enable_auto_optimization = True
        self.optimization_threshold = 3  # 3ë²ˆ ëŒ€í™” í›„ ìµœì í™”
        
        # ë¿Œë¦¬ì‚°ì—… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = self._create_system_prompt()
        
        # ëŒ€í™” í†µê³„
        self.conversation_stats = {
            "total_conversations": 0,
            "total_sessions": 0,
            "avg_response_time": 0.0,
            "optimization_success_rate": 0.0
        }
        
        logger.info("Conversational Engine ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def initialize(self):
        """ì—”ì§„ ì´ˆê¸°í™”"""
        
        # Ollama ì—°ê²° ì´ˆê¸°í™”
        self.ollama_session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=self.ollama_config["timeout"])
        )
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        await self._test_ollama_connection()
        
        logger.info("Conversational Engine ì´ˆê¸°í™” ë° ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.ollama_session:
            await self.ollama_session.close()
        
        # ì„¸ì…˜ ì •ë¦¬
        self.active_sessions.clear()
        
        logger.info("Conversational Engine ì •ë¦¬ ì™„ë£Œ")
    
    def _create_system_prompt(self) -> str:
        """ë¿Œë¦¬ì‚°ì—… íŠ¹í™” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        return """ë‹¹ì‹ ì€ ë¿Œë¦¬ì‚°ì—… ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ 'ë¿Œë¦¬ì•„ì´(PPuRI-AI)'ì…ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼**: ì£¼ì¡°, ê¸ˆí˜•, ì†Œì„±ê°€ê³µ, ìš©ì ‘, í‘œë©´ì²˜ë¦¬, ì—´ì²˜ë¦¬
**ì—­í• **: ë¿Œë¦¬ì‚°ì—… ê¸°ìˆ  ìƒë‹´, ë¬¸ì œ í•´ê²°, ì§€ì‹ ì „ë‹¬

**ì‘ë‹µ ì›ì¹™**:
1. ğŸ¯ **ì •í™•ì„±**: ê¸°ìˆ ì ìœ¼ë¡œ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ ì œê³µ
2. ğŸ‡°ğŸ‡· **í•œêµ­ì–´ ìµœì í™”**: ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í•œêµ­ì–´ ì‚¬ìš©
3. ğŸ­ **ì‹¤ë¬´ ì¤‘ì‹¬**: í˜„ì¥ì—ì„œ ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ êµ¬ì²´ì  ì†”ë£¨ì…˜
4. ğŸ“š **êµìœ¡ì **: ì›ë¦¬ì™€ ë°°ê²½ì„ í•¨ê»˜ ì„¤ëª…í•˜ì—¬ í•™ìŠµ íš¨ê³¼ ê·¹ëŒ€í™”
5. ğŸ”§ **ë¬¸ì œ í•´ê²°**: ë‹¨ê³„ì ì´ê³  ì²´ê³„ì ì¸ ë¬¸ì œ í•´ê²° ì ‘ê·¼

**íŠ¹ë³„ ì§€ì‹œ**:
- ì „ë¬¸ ìš©ì–´ëŠ” í•œêµ­ì–´ ìš°ì„ , í•„ìš”ì‹œ ì˜ì–´/í•œì ë³‘ê¸°
- ìˆ˜ì¹˜ì™€ ê¸°ì¤€ì€ êµ­ì œ í‘œì¤€ ë° êµ­ë‚´ ê¸°ì¤€ ëª¨ë‘ ì œì‹œ
- ì•ˆì „ ê´€ë ¨ ë‚´ìš©ì€ ë°˜ë“œì‹œ ê°•ì¡°
- ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ ëª…í™•íˆ í‘œì‹œí•˜ê³  ì¶”ê°€ í™•ì¸ ê¶Œì¥

ì§€ê¸ˆë¶€í„° ë¿Œë¦¬ì‚°ì—… ì „ë¬¸ê°€ë¡œì„œ ìµœê³  í’ˆì§ˆì˜ ê¸°ìˆ  ìƒë‹´ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
    
    async def _test_ollama_connection(self) -> bool:
        """Ollama ì—°ê²° í…ŒìŠ¤íŠ¸"""
        
        try:
            health_url = self.ollama_config["api_url"].replace("/api/generate", "/api/tags")
            
            async with self.ollama_session.get(health_url) as response:
                if response.status == 200:
                    logger.info("âœ… Ollama ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                    return True
                else:
                    logger.warning(f"âš ï¸ Ollama ì‘ë‹µ ìƒíƒœ ì´ìƒ: {response.status}")
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ Ollama ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    async def start_conversation(
        self,
        user_id: Optional[str] = None,
        initial_context: Optional[Dict[str, Any]] = None
    ) -> str:
        """ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ ì‹œì‘"""
        
        session_id = str(uuid.uuid4())
        
        session = ConversationSession(
            session_id=session_id,
            user_id=user_id,
            context=initial_context or {}
        )
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
        session.messages.append(ConversationMessage(
            role="system",
            content=self.system_prompt
        ))
        
        self.active_sessions[session_id] = session
        self.conversation_stats["total_sessions"] += 1
        
        # THINK ì„¸ì…˜ ì‹œì‘
        await self.think_manager.start_think_session(session_id, initial_context)
        
        logger.info(f"ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ ì‹œì‘: {session_id}")
        return session_id
    
    async def chat(
        self,
        session_id: str,
        user_message: str,
        stream: bool = True
    ) -> AsyncGenerator[ConversationResult, None]:
        """
        ì‚¬ìš©ìì™€ ëŒ€í™” ì§„í–‰
        
        Args:
            session_id: ëŒ€í™” ì„¸ì…˜ ID
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            stream: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì—¬ë¶€
            
        Yields:
            ConversationResult: ëŒ€í™” ê²°ê³¼ (ìŠ¤íŠ¸ë¦¬ë° ì‹œ ë¶€ë¶„ ê²°ê³¼)
        """
        
        start_time = time.time()
        
        try:
            # 1. ì„¸ì…˜ ìœ íš¨ì„± í™•ì¸
            if session_id not in self.active_sessions:
                yield ConversationResult(
                    response="âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”.",
                    session_id=session_id,
                    processing_time=0.0
                )
                return
            
            session = self.active_sessions[session_id]
            session.last_activity = datetime.now()
            
            # 2. ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            user_msg = ConversationMessage(
                role="user",
                content=user_message
            )
            session.messages.append(user_msg)
            
            # 3. í•œêµ­ì–´ ì²˜ë¦¬ ë° ë¶„ì„
            korean_result = await self.korean_optimizer.process_korean_text(user_message)
            
            # ë¿Œë¦¬ì‚°ì—… ë„ë©”ì¸ ê°ì§€
            if korean_result.industry_terms:
                # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì¹´í…Œê³ ë¦¬ ì¶”ì •
                categories = [
                    self.korean_optimizer.industry_terms[term].category 
                    for term in korean_result.industry_terms 
                    if term in self.korean_optimizer.industry_terms
                ]
                if categories:
                    from collections import Counter
                    session.industry_domain = Counter(categories).most_common(1)[0][0]
            
            # 4. í”„ë¡¬í”„íŠ¸ ìµœì í™” (í•„ìš”ì‹œ)
            optimized_prompt = await self._get_optimized_prompt(session, user_message)
            optimization_applied = optimized_prompt != user_message
            
            # 5. THINK ë¸”ë¡ ìƒì„± ì‹œì‘
            think_blocks = []
            if self.think_manager.enabled:
                async for think_block in self.think_manager.generate_progressive_think(
                    session_id, user_message, session.industry_domain
                ):
                    think_blocks.append({
                        "level": think_block.level.value,
                        "content": think_block.content,
                        "timestamp": think_block.timestamp.isoformat()
                    })
                    
                    if stream:
                        # THINK ë¸”ë¡ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ì†¡
                        yield ConversationResult(
                            response=self.think_manager.format_think_block_for_display(think_block),
                            session_id=session_id,
                            processing_time=time.time() - start_time,
                            think_blocks=[think_blocks[-1]]
                        )
            
            # 6. Ollamaë¡œ ì‘ë‹µ ìƒì„±
            if stream:
                async for partial_result in self._generate_streaming_response(
                    session, optimized_prompt, start_time, optimization_applied, 
                    korean_result.industry_terms, think_blocks
                ):
                    yield partial_result
            else:
                final_result = await self._generate_single_response(
                    session, optimized_prompt, start_time, optimization_applied,
                    korean_result.industry_terms, think_blocks
                )
                yield final_result
                
        except Exception as e:
            logger.error(f"ëŒ€í™” ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            yield ConversationResult(
                response=f"âŒ ëŒ€í™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                session_id=session_id,
                processing_time=time.time() - start_time
            )
    
    async def _get_optimized_prompt(
        self, 
        session: ConversationSession, 
        user_message: str
    ) -> str:
        """í”„ë¡¬í”„íŠ¸ ìµœì í™”"""
        
        if not self.auto_optimizer or not self.enable_auto_optimization:
            return user_message
        
        # ì¼ì • ëŒ€í™” ìˆ˜ ì´í›„ë¶€í„° ìµœì í™” ì ìš©
        if len(session.messages) < self.optimization_threshold:
            return user_message
        
        try:
            # ìµœì í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = {
                "user_profile": session.context.get("user_profile", {}),
                "conversation_history": [
                    {"role": msg.role, "content": msg.content[:200]}  # ì²˜ìŒ 200ìë§Œ
                    for msg in session.messages[-5:]  # ìµœê·¼ 5ê°œ ë©”ì‹œì§€ë§Œ
                ],
                "industry_domain": session.industry_domain,
                "success_patterns": session.optimization_state.get("success_patterns", [])
            }
            
            # AdalFlow ìµœì í™” ì‹¤í–‰
            optimization_result = await self.auto_optimizer.optimize_prompt(
                prompt=user_message,
                context=context,
                target_domain=session.industry_domain or "ë¿Œë¦¬ì‚°ì—…"
            )
            
            # ìµœì í™” ê²°ê³¼ ì €ì¥
            session.optimization_state["last_optimization"] = {
                "original": user_message,
                "optimized": optimization_result.optimized_prompt,
                "performance_gain": optimization_result.performance_gain,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"í”„ë¡¬í”„íŠ¸ ìµœì í™” ì ìš©: +{optimization_result.performance_gain:.1f}%")
            return optimization_result.optimized_prompt
            
        except Exception as e:
            logger.error(f"í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹¤íŒ¨: {e}")
            return user_message
    
    async def _generate_streaming_response(
        self,
        session: ConversationSession,
        prompt: str,
        start_time: float,
        optimization_applied: bool,
        industry_terms: List[str],
        think_blocks: List[Dict[str, Any]]
    ) -> AsyncGenerator[ConversationResult, None]:
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±"""
        
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
            messages = self._build_conversation_history(session, prompt)
            
            # Ollama ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­
            request_data = {
                "model": self.ollama_config["model"],
                "messages": messages,
                "stream": True,
                "options": self.ollama_config["options"]
            }
            
            full_response = ""
            
            async with self.ollama_session.post(
                self.ollama_config["api_url"].replace("/api/generate", "/api/chat"),
                json=request_data
            ) as response:
                
                async for line in response.content:
                    if line:
                        try:
                            data = json.loads(line.decode().strip())
                            
                            if "message" in data and "content" in data["message"]:
                                chunk = data["message"]["content"]
                                full_response += chunk
                                
                                yield ConversationResult(
                                    response=chunk,
                                    session_id=session.session_id,
                                    processing_time=time.time() - start_time,
                                    optimization_applied=optimization_applied,
                                    industry_terms_detected=industry_terms,
                                    think_blocks=think_blocks
                                )
                            
                            # ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ í™•ì¸
                            if data.get("done", False):
                                break
                                
                        except json.JSONDecodeError:
                            continue
            
            # ì‘ë‹µ ì™„ë£Œ í›„ ì²˜ë¦¬
            await self._post_process_response(
                session, full_response, start_time, optimization_applied, industry_terms
            )
            
        except Exception as e:
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            yield ConversationResult(
                response=f"âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                session_id=session.session_id,
                processing_time=time.time() - start_time
            )
    
    async def _generate_single_response(
        self,
        session: ConversationSession,
        prompt: str,
        start_time: float,
        optimization_applied: bool,
        industry_terms: List[str],
        think_blocks: List[Dict[str, Any]]
    ) -> ConversationResult:
        """ë‹¨ì¼ ì‘ë‹µ ìƒì„±"""
        
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
            messages = self._build_conversation_history(session, prompt)
            
            # Ollama ìš”ì²­
            request_data = {
                "model": self.ollama_config["model"],
                "messages": messages,
                "stream": False,
                "options": self.ollama_config["options"]
            }
            
            async with self.ollama_session.post(
                self.ollama_config["api_url"].replace("/api/generate", "/api/chat"),
                json=request_data
            ) as response:
                
                if response.status == 200:
                    result = await response.json()
                    ai_response = result["message"]["content"]
                    
                    # ì‘ë‹µ í›„ì²˜ë¦¬
                    await self._post_process_response(
                        session, ai_response, start_time, optimization_applied, industry_terms
                    )
                    
                    return ConversationResult(
                        response=ai_response,
                        session_id=session.session_id,
                        processing_time=time.time() - start_time,
                        optimization_applied=optimization_applied,
                        industry_terms_detected=industry_terms,
                        think_blocks=think_blocks
                    )
                else:
                    raise Exception(f"Ollama API ì˜¤ë¥˜: {response.status}")
            
        except Exception as e:
            logger.error(f"ë‹¨ì¼ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return ConversationResult(
                response=f"âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                session_id=session.session_id,
                processing_time=time.time() - start_time
            )
    
    def _build_conversation_history(
        self, 
        session: ConversationSession, 
        current_prompt: str
    ) -> List[Dict[str, str]]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±"""
        
        messages = []
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€
        if session.messages and session.messages[0].role == "system":
            messages.append({
                "role": "system",
                "content": session.messages[0].content
            })
        
        # ìµœê·¼ ëŒ€í™” (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì œí•œ)
        recent_messages = session.messages[-10:]  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€
        
        for msg in recent_messages:
            if msg.role != "system":  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ì´ë¯¸ ì¶”ê°€ë¨
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })
        
        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ (ì•„ì§ ì„¸ì…˜ì— ì¶”ê°€ë˜ì§€ ì•Šì€ ê²½ìš°)
        if not messages or messages[-1]["content"] != current_prompt:
            messages.append({
                "role": "user", 
                "content": current_prompt
            })
        
        return messages
    
    async def _post_process_response(
        self,
        session: ConversationSession,
        ai_response: str,
        start_time: float,
        optimization_applied: bool,
        industry_terms: List[str]
    ):
        """ì‘ë‹µ í›„ì²˜ë¦¬"""
        
        # AI ì‘ë‹µì„ ì„¸ì…˜ì— ì¶”ê°€
        ai_msg = ConversationMessage(
            role="assistant",
            content=ai_response,
            metadata={
                "optimization_applied": optimization_applied,
                "industry_terms": industry_terms,
                "processing_time": time.time() - start_time
            }
        )
        session.messages.append(ai_msg)
        
        # ì„±ëŠ¥ ì¶”ì  (ê°€ëŠ¥í•œ ê²½ìš°)
        if self.performance_tracker:
            await self.performance_tracker.track_interaction(
                session_id=session.session_id,
                prompt=session.messages[-2].content if len(session.messages) >= 2 else "",
                response=ai_response,
                user_id=session.user_id,
                context={
                    "optimization_applied": optimization_applied,
                    "industry_terms": industry_terms,
                    "response_time": time.time() - start_time
                }
            )
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self._update_conversation_stats(time.time() - start_time, optimization_applied)
        
        # ì„¸ì…˜ ìë™ ì •ë¦¬ (ë„ˆë¬´ ê¸¸ì–´ì§„ ê²½ìš°)
        if len(session.messages) > 50:  # ë©”ì‹œì§€ê°€ 50ê°œ ì´ìƒì´ë©´
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ + ìµœê·¼ 30ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€
            system_msg = session.messages[0] if session.messages[0].role == "system" else None
            recent_msgs = session.messages[-30:]
            
            session.messages = ([system_msg] if system_msg else []) + recent_msgs
            logger.info(f"ì„¸ì…˜ {session.session_id} ë©”ì‹œì§€ ì •ë¦¬ ì™„ë£Œ")
    
    def _update_conversation_stats(self, processing_time: float, optimization_applied: bool):
        """ëŒ€í™” í†µê³„ ì—…ë°ì´íŠ¸"""
        
        self.conversation_stats["total_conversations"] += 1
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
        total = self.conversation_stats["total_conversations"]
        current_avg = self.conversation_stats["avg_response_time"]
        
        self.conversation_stats["avg_response_time"] = (
            (current_avg * (total - 1) + processing_time) / total
        )
        
        # ìµœì í™” ì„±ê³µë¥  ì—…ë°ì´íŠ¸
        if optimization_applied:
            current_rate = self.conversation_stats["optimization_success_rate"]
            self.conversation_stats["optimization_success_rate"] = (
                (current_rate * (total - 1) + 1.0) / total
            )
        else:
            current_rate = self.conversation_stats["optimization_success_rate"]
            self.conversation_stats["optimization_success_rate"] = (
                current_rate * (total - 1) / total
            )
    
    async def end_conversation(self, session_id: str) -> Optional[Dict[str, Any]]:
        """ëŒ€í™” ì„¸ì…˜ ì¢…ë£Œ"""
        
        if session_id not in self.active_sessions:
            return None
        
        session = self.active_sessions[session_id]
        
        # THINK ì„¸ì…˜ ì¢…ë£Œ
        think_stats = self.think_manager.end_think_session(session_id)
        
        # ì„¸ì…˜ í†µê³„ ìƒì„±
        session_stats = {
            "session_id": session_id,
            "user_id": session.user_id,
            "duration": (datetime.now() - session.start_time).total_seconds(),
            "total_messages": len(session.messages),
            "industry_domain": session.industry_domain,
            "optimization_applied_count": len([
                msg for msg in session.messages 
                if msg.metadata.get("optimization_applied", False)
            ]),
            "think_stats": think_stats,
            "end_time": datetime.now().isoformat()
        }
        
        # ì„¸ì…˜ ì‚­ì œ
        del self.active_sessions[session_id]
        
        logger.info(f"ëŒ€í™” ì„¸ì…˜ ì¢…ë£Œ: {session_id} - {session_stats['total_messages']}ê°œ ë©”ì‹œì§€")
        return session_stats
    
    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:
        """ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
        
        if session_id not in self.active_sessions:
            return None
        
        session = self.active_sessions[session_id]
        
        return {
            "session_id": session_id,
            "user_id": session.user_id,
            "start_time": session.start_time.isoformat(),
            "last_activity": session.last_activity.isoformat(),
            "message_count": len(session.messages),
            "industry_domain": session.industry_domain,
            "context": session.context,
            "optimization_state": session.optimization_state
        }
    
    def get_conversation_stats(self) -> Dict[str, Any]:
        """ëŒ€í™” í†µê³„ ì¡°íšŒ"""
        
        active_sessions_count = len(self.active_sessions)
        
        return {
            **self.conversation_stats,
            "active_sessions": active_sessions_count,
            "engine_config": {
                "auto_optimization_enabled": self.enable_auto_optimization,
                "optimization_threshold": self.optimization_threshold,
                "session_timeout_hours": self.session_timeout.total_seconds() / 3600
            },
            "ollama_config": {
                "model": self.ollama_config["model"],
                "api_url": self.ollama_config["api_url"]
            },
            "last_updated": datetime.now().isoformat()
        }
    
    async def cleanup_expired_sessions(self):
        """ë§Œë£Œëœ ì„¸ì…˜ ì •ë¦¬"""
        
        current_time = datetime.now()
        expired_sessions = []
        
        for session_id, session in self.active_sessions.items():
            if current_time - session.last_activity > self.session_timeout:
                expired_sessions.append(session_id)
        
        for session_id in expired_sessions:
            await self.end_conversation(session_id)
            
        if expired_sessions:
            logger.info(f"ë§Œë£Œëœ ì„¸ì…˜ {len(expired_sessions)}ê°œ ì •ë¦¬ ì™„ë£Œ")
    
    async def export_conversation_history(
        self, 
        session_id: str, 
        format: str = "json"
    ) -> Optional[Dict[str, Any]]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ë‚´ë³´ë‚´ê¸°"""
        
        if session_id not in self.active_sessions:
            return None
        
        session = self.active_sessions[session_id]
        
        if format == "json":
            return {
                "session_info": {
                    "session_id": session_id,
                    "user_id": session.user_id,
                    "start_time": session.start_time.isoformat(),
                    "industry_domain": session.industry_domain
                },
                "messages": [
                    {
                        "role": msg.role,
                        "content": msg.content,
                        "timestamp": msg.timestamp.isoformat(),
                        "metadata": msg.metadata,
                        "think_blocks": msg.think_blocks
                    }
                    for msg in session.messages
                ],
                "context": session.context,
                "optimization_state": session.optimization_state,
                "export_timestamp": datetime.now().isoformat()
            }
        
        return None