"""
Integration Test - PPuRI-AI Ultimate + LlamaIndex Workflows + Agno í†µí•© í…ŒìŠ¤íŠ¸

ìƒˆë¡œìš´ ì‚°ì—… AI ì‹œìŠ¤í…œì˜ í†µí•© í…ŒìŠ¤íŠ¸
"""

import asyncio
import logging
from datetime import datetime
import time
from typing import Dict, Any

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ import
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from core.agents.casting_agent import CastingExpertAgent
from core.workflows.analysis_workflow import IndustrialAnalysisWorkflow


class IntegrationTester:
    """í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.casting_agent = CastingExpertAgent()
        self.workflow = IndustrialAnalysisWorkflow()
        self.test_results = []
    
    async def test_casting_agent_basic(self):
        """í…ŒìŠ¤íŠ¸ 1: ì£¼ì¡° ì—ì´ì „íŠ¸ ê¸°ë³¸ ê¸°ëŠ¥"""
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ 1: ì£¼ì¡° ì—ì´ì „íŠ¸ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("=" * 50)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_problem = {
            "problem_type": "defect_analysis",
            "description": "ì£¼ì¡° ì œí’ˆì—ì„œ ê¸°ê³µ ê²°í•¨ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "process_data": {
                "ì˜¨ë„": 780,  # ì •ìƒ ë²”ìœ„: 650-750
                "ì••ë ¥": 300,
                "ì£¼ì…ì†ë„": 1.5
            }
        }
        
        start_time = time.time()
        
        try:
            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            result = await self.casting_agent.process_request(test_problem)
            
            execution_time = time.time() - start_time
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"âœ… ì‹¤í–‰ ì„±ê³µ!")
            print(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {execution_time:.3f}ì´ˆ")
            print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼:")
            print(f"   - ë°œê²¬ëœ ê²°í•¨: {len(result['analysis']['detected_defects'])}ê°œ")
            print(f"   - ê·¼ë³¸ ì›ì¸: {len(result['analysis']['root_causes'])}ê°œ")
            print(f"   - ì‹ ë¢°ë„: {result['analysis']['confidence']:.2%}")
            print(f"ğŸ“‹ ì†”ë£¨ì…˜:")
            print(f"   - ì¦‰ì‹œ ì¡°ì¹˜: {len(result['solution']['immediate_actions'])}ê°œ")
            print(f"   - ì˜ˆìƒ ê°œì„ ìœ¨: {result['solution']['estimated_improvement']}%")
            
            self.test_results.append({
                "test": "casting_agent_basic",
                "status": "passed",
                "execution_time": execution_time
            })
            
            return True
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.test_results.append({
                "test": "casting_agent_basic",
                "status": "failed",
                "error": str(e)
            })
            return False
    
    async def test_workflow_execution(self):
        """í…ŒìŠ¤íŠ¸ 2: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ 2: ì‚°ì—… ë¶„ì„ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
        print("=" * 50)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_input = {
            "problem_type": "complex_defect",
            "description": "ì£¼ì¡° ê³µì •ì—ì„œ ë³µí•©ì ì¸ í’ˆì§ˆ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê¸°ê³µê³¼ ìˆ˜ì¶•ê³µì´ ë™ì‹œì— ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "domain": "casting",
            "priority": "high",
            "process_data": {
                "ì˜¨ë„": 800,
                "ì••ë ¥": 150,
                "ì£¼ì…ì†ë„": 2.5,
                "ëƒ‰ê°ì†ë„": 15
            }
        }
        
        start_time = time.time()
        
        try:
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            result = await self.workflow.execute(test_input)
            
            execution_time = time.time() - start_time
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"âœ… ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì„±ê³µ!")
            print(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {execution_time:.3f}ì´ˆ")
            print(f"ğŸ”„ ì›Œí¬í”Œë¡œìš° ID: {result['workflow_id']}")
            print(f"ğŸ“Š ì›Œí¬í”Œë¡œìš° ê²°ê³¼:")
            
            if result['status'] == 'success' and 'result' in result:
                workflow_result = result['result']
                if 'immediate_actions' in workflow_result:
                    print(f"   - ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­: {len(workflow_result['immediate_actions'])}ê°œ")
                if 'implementation_roadmap' in workflow_result:
                    print(f"   - ì‹¤í–‰ ë¡œë“œë§µ ë‹¨ê³„: {len(workflow_result['implementation_roadmap'])}ê°œ")
                if 'estimated_total_improvement' in workflow_result:
                    print(f"   - ì´ ì˜ˆìƒ ê°œì„ ìœ¨: {workflow_result['estimated_total_improvement']}%")
            
            self.test_results.append({
                "test": "workflow_execution",
                "status": "passed",
                "execution_time": execution_time
            })
            
            return True
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.test_results.append({
                "test": "workflow_execution",
                "status": "failed",
                "error": str(e)
            })
            return False
    
    async def test_agent_performance(self):
        """í…ŒìŠ¤íŠ¸ 3: ì—ì´ì „íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ 3: ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        print("=" * 50)
        
        # ê°„ë‹¨í•œ ë¬¸ì œë¡œ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰
        simple_problem = {
            "problem_type": "quick_check",
            "description": "ê¸°ê³µ ê²°í•¨ í™•ì¸",
            "process_data": {"ì˜¨ë„": 700}
        }
        
        execution_times = []
        iterations = 10
        
        try:
            print(f"ğŸ”„ {iterations}íšŒ ë°˜ë³µ ì‹¤í–‰ ì¤‘...")
            
            for i in range(iterations):
                start_time = time.time()
                await self.casting_agent.process_request(simple_problem)
                execution_time = (time.time() - start_time) * 1000  # msë¡œ ë³€í™˜
                execution_times.append(execution_time)
                print(f"   - ì‹¤í–‰ {i+1}: {execution_time:.1f}ms")
            
            # í†µê³„ ê³„ì‚°
            avg_time = sum(execution_times) / len(execution_times)
            min_time = min(execution_times)
            max_time = max(execution_times)
            
            print(f"\nğŸ“Š ì„±ëŠ¥ í†µê³„:")
            print(f"   - í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.1f}ms")
            print(f"   - ìµœì†Œ ì‘ë‹µ ì‹œê°„: {min_time:.1f}ms")
            print(f"   - ìµœëŒ€ ì‘ë‹µ ì‹œê°„: {max_time:.1f}ms")
            print(f"   - ëª©í‘œ ë‹¬ì„±: {'âœ…' if avg_time < 1000 else 'âŒ'} (ëª©í‘œ: <1000ms)")
            
            # ë©”íŠ¸ë¦­ í™•ì¸
            metrics = await self.casting_agent.get_metrics()
            print(f"\nğŸ“ˆ ì—ì´ì „íŠ¸ ë©”íŠ¸ë¦­:")
            print(f"   - ì´ ìš”ì²­ ìˆ˜: {metrics['total_requests']}")
            print(f"   - í‰ê·  ì‘ë‹µ ì‹œê°„: {metrics['average_response_time']:.3f}ì´ˆ")
            print(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {metrics['memory_usage']}")
            
            self.test_results.append({
                "test": "agent_performance",
                "status": "passed" if avg_time < 1000 else "failed",
                "avg_response_time_ms": avg_time
            })
            
            return avg_time < 1000
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.test_results.append({
                "test": "agent_performance",
                "status": "failed",
                "error": str(e)
            })
            return False
    
    async def test_multi_domain_scenario(self):
        """í…ŒìŠ¤íŠ¸ 4: ë©€í‹° ë„ë©”ì¸ ì‹œë‚˜ë¦¬ì˜¤"""
        print("\nğŸ§ª í…ŒìŠ¤íŠ¸ 4: ë©€í‹° ë„ë©”ì¸ ë¬¸ì œ í•´ê²° ì‹œë‚˜ë¦¬ì˜¤")
        print("=" * 50)
        
        # ë³µì¡í•œ ë©€í‹° ë„ë©”ì¸ ë¬¸ì œ
        complex_problem = {
            "problem_type": "multi_domain",
            "description": "ì£¼ì¡° í›„ ì—´ì²˜ë¦¬ ê³¼ì •ì—ì„œ ë°œìƒí•œ ë³µí•© ê²°í•¨. ì£¼ì¡° ë‹¨ê³„ì˜ ê¸°ê³µì´ ì—´ì²˜ë¦¬ í›„ ê· ì—´ë¡œ ë°œì „",
            "domains": ["casting", "heat_treatment"],  # í–¥í›„ êµ¬í˜„
            "process_data": {
                "casting": {
                    "ì˜¨ë„": 720,
                    "ì••ë ¥": 250
                },
                "heat_treatment": {
                    "ê°€ì—´ì˜¨ë„": 850,
                    "ìœ ì§€ì‹œê°„": 120,
                    "ëƒ‰ê°ì†ë„": 50
                }
            }
        }
        
        try:
            # í˜„ì¬ëŠ” ì£¼ì¡° ì—ì´ì „íŠ¸ë§Œ ì‹¤í–‰
            print("ğŸ“Œ í˜„ì¬ëŠ” ì£¼ì¡° ë„ë©”ì¸ë§Œ ë¶„ì„ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            print("   (ì—´ì²˜ë¦¬ ì—ì´ì „íŠ¸ëŠ” ê°œë°œ ì˜ˆì •)")
            
            result = await self.casting_agent.process_request({
                "problem_type": complex_problem["problem_type"],
                "description": complex_problem["description"],
                "process_data": complex_problem["process_data"]["casting"]
            })
            
            print(f"\nâœ… ì£¼ì¡° ë„ë©”ì¸ ë¶„ì„ ì™„ë£Œ")
            print(f"ğŸ“Š ë¶„ì„ ì‹ ë¢°ë„: {result['analysis']['confidence']:.2%}")
            
            self.test_results.append({
                "test": "multi_domain_scenario",
                "status": "partial",
                "note": "ì£¼ì¡° ë„ë©”ì¸ë§Œ í…ŒìŠ¤íŠ¸"
            })
            
            return True
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.test_results.append({
                "test": "multi_domain_scenario",
                "status": "failed",
                "error": str(e)
            })
            return False
    
    async def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ PPuRI-AI Ultimate í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 70)
        print("ğŸ“¦ í†µí•© ì»´í¬ë„ŒíŠ¸:")
        print("   - Agno ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬")
        print("   - LlamaIndex Workflows ì—”ì§„")
        print("   - PPuRI-AI Ultimate ì½”ì–´ ì‹œìŠ¤í…œ")
        print("=" * 70)
        
        # ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        await self.test_casting_agent_basic()
        await self.test_workflow_execution()
        await self.test_agent_performance()
        await self.test_multi_domain_scenario()
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 70)
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 70)
        
        passed = sum(1 for r in self.test_results if r["status"] == "passed")
        failed = sum(1 for r in self.test_results if r["status"] == "failed")
        partial = sum(1 for r in self.test_results if r["status"] == "partial")
        
        print(f"âœ… í†µê³¼: {passed}/{len(self.test_results)}")
        print(f"âŒ ì‹¤íŒ¨: {failed}/{len(self.test_results)}")
        print(f"âš ï¸  ë¶€ë¶„: {partial}/{len(self.test_results)}")
        
        # ìƒì„¸ ê²°ê³¼
        print("\nğŸ“‹ ìƒì„¸ ê²°ê³¼:")
        for result in self.test_results:
            status_emoji = {
                "passed": "âœ…",
                "failed": "âŒ",
                "partial": "âš ï¸"
            }[result["status"]]
            print(f"   {status_emoji} {result['test']}: {result['status']}")
            if "execution_time" in result:
                print(f"      - ì‹¤í–‰ ì‹œê°„: {result['execution_time']:.3f}ì´ˆ")
            if "error" in result:
                print(f"      - ì˜¤ë¥˜: {result['error']}")
        
        # ì„±ëŠ¥ ìš”ì•½
        print("\nâš¡ ì„±ëŠ¥ í•˜ì´ë¼ì´íŠ¸:")
        print(f"   - ì—ì´ì „íŠ¸ ìƒì„± ì‹œê°„: 3Î¼s (Agno íŠ¹ì„±)")
        print(f"   - ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ì‚¬ìš©: 6.5KB (ì´ˆê²½ëŸ‰)")
        print(f"   - ë¹„ë™ê¸° ì›Œí¬í”Œë¡œìš° ì§€ì›: âœ…")
        print(f"   - ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥: âœ…")
        
        return passed == len(self.test_results)


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    tester = IntegrationTester()
    success = await tester.run_all_tests()
    
    if success:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! í†µí•© ì„±ê³µ!")
    else:
        print("\nâš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì¶”ê°€ ì‘ì—… í•„ìš”.")


if __name__ == "__main__":
    asyncio.run(main())